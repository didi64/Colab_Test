{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNT3x+MA4GRr4+GX8f/RSSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/didi64/Colab_Test/blob/main/Classify_Reviews2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the cleaned reviews and train an LSTM-model"
      ],
      "metadata": {
        "id": "8LMKuWsqK3nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dXRgHF-nNaJ",
        "outputId": "47c6fe38-91a1-4463-cffd-5340a7d1754d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "ROOT = '/content/drive/MyDrive/CAS_Gregi/'\n",
        "IMPORT_PATH_SYMLINK = {'link': '/content/modules', 'target': ROOT + 'CO_modules'}\n",
        "\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "if not os.path.exists(IMPORT_PATH_SYMLINK['link']):\n",
        "    os.symlink(IMPORT_PATH_SYMLINK['target'], IMPORT_PATH_SYMLINK['link'])\n",
        "if IMPORT_PATH_SYMLINK['link'] not in sys.path:\n",
        "    sys.path.insert(0, IMPORT_PATH_SYMLINK['link'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l {IMPORT_PATH_SYMLINK['link']}\n",
        "!ls /content $ROOT /content/drive {IMPORT_PATH_SYMLINK['link']}"
      ],
      "metadata": {
        "id": "iRED4e1XBIDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(ROOT + 'data/hotelreviews_cleaned_train_test_spell.pkl','rb') as f:\n",
        "    data_train, data_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "1vIHgPwxnWNA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from functools import reduce"
      ],
      "metadata": {
        "id": "CG5uUG2knoQC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_shape(text):\n",
        "    return tf.constant(text, shape = (1,))\n",
        "\n",
        "def get_dataset(d):\n",
        "    ''' get dataset from dict {score: list_of_revies,...}'''\n",
        "    # list of tuples [(score, review),...]\n",
        "    all_reviews = reduce(lambda x,y: x + y, [[(r, k) for k,v in d.items() for r in v]])\n",
        "    random.shuffle(all_reviews)\n",
        "    reviews = tf.constant([r for r,_ in all_reviews], shape=(len(all_reviews), 1))\n",
        "    gpt_scores  = tf.constant([s - 1 for _, s in all_reviews])\n",
        "\n",
        "    n = len(reviews)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((reviews[:n], gpt_scores[:n]))\n",
        "    return ds\n",
        "\n",
        "def batch(ds, batch_size = 32):\n",
        "    xs, ys =  next(iter(ds))\n",
        "    if xs.shape == () or xs.shape[0] == 1:\n",
        "        ds = ds.batch(batch_size)\n",
        "    return ds\n",
        "\n",
        "def test_model(model, ds):\n",
        "    i = 0\n",
        "    for xs, _ in iter(ds):\n",
        "        i += 1\n",
        "        if (i %10) ==0:\n",
        "            print(i, end = ', ')\n",
        "        model(xs)"
      ],
      "metadata": {
        "id": "pcfrpwo-oBSa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = batch(get_dataset(data_train))\n",
        "ds_test  = batch(get_dataset(data_test))"
      ],
      "metadata": {
        "id": "90g9QwfIp1pC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_reviews = reduce(lambda x,y: x + y, [[(r, k) for d in (data_train, data_test) for k,v in d.items() for r in v]])\n",
        "WORDS = reduce(lambda x,y:x|y, [set(x[0].split()) for x in all_reviews])"
      ],
      "metadata": {
        "id": "f31svtLJqCgy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocab Size, number of review, fraction of reviews with more than 200 words\n",
        "len(WORDS), len(all_reviews), len([nwords for x in all_reviews if (nwords := len(x[0].split())) > 200])/len(all_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPcDw3KGqfz0",
        "outputId": "99c487a5-af6c-4df2-b0e6-b876a0daaa2f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9033, 6000, 0.029)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B97JfqHQQSJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardization: one element of  standardizations or a callable mapping strings to strings\n",
        "standardizations = [None, \"lower_and_strip_punctuation\", \"lower\", \"strip_punctuation\"]\n",
        "max_tokens = len(WORDS) + 2 # number of words plus the tokens '' and '[UNK]'\n",
        "ngrams = None\n",
        "sequence_length = 200\n",
        "\n",
        "tv_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens = max_tokens,\n",
        "    standardize = standardizations[0],\n",
        "    ngrams=ngrams,\n",
        "    output_mode='int',\n",
        "    output_sequence_length = sequence_length,\n",
        "    pad_to_max_tokens=True,\n",
        ")"
      ],
      "metadata": {
        "id": "JoS_4NYuq2Gz"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_layer.adapt([r[0] for r in all_reviews])\n",
        "vocab = tv_layer.get_vocabulary()\n",
        "len(vocab),  vocab[:5]# max_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BYO96FPrnf1",
        "outputId": "ffe21be8-c8ca-4ff7-b692-9d73780b56d1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9035, ['', '[UNK]', 'the', 'and', 'was'])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv_layer(data_train[3][30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhyvW7rFr3k1",
        "outputId": "738a6a74-6a3f-4196-84d5-9d91ac28583e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(200,), dtype=int64, numpy=\n",
              "array([  16,    8,  436,   82,  163,    5,  365,  222,   37,   21,    2,\n",
              "        377,  259,   36,   20,    5,  276,   10,  104, 2640,   21,    2,\n",
              "        377,  466,   16,   20,  528,    2,  207,   55,    5,  118,  275,\n",
              "          3,   44,  105,  210,  192, 1695,    6,  316,    8,    2,  115,\n",
              "          7,   13,    2,   94,   25,   65,  264,   42,  367,    3,  586,\n",
              "          5,  664,    4,  392,    8,    2,    7,   36,   14,   40, 1155,\n",
              "        107,  316,   17,  429,   29,  296,    5,  531,    3,    5,  357,\n",
              "        113,   28,   89,   28,  291,  398,    6, 4099,    5, 1109, 3744,\n",
              "          2,    7,    4,   52,    3,  722,    3,    2,   41,    4,   98,\n",
              "         30,  106,  544,    8,    2,   67,    3,  738,  585, 1656,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[16], vocab[8], vocab[436], data_train[3][30].split()[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV9vWRafSjjj",
        "outputId": "096e907b-a74e-40a9-ea3b-c0d1bf8382dc"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('it', 'in', 'located', ['it', 'in', 'located'])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim =  16\n",
        "em_layer = tf.keras.layers.Embedding(input_dim = max_tokens + 1, output_dim= output_dim)\n",
        "em_layer(tv_layer('what a hotel'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOJlXkTIsHa0",
        "outputId": "b841119a-dbe5-48de-99d7-ced2ce423a3c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(200, 16), dtype=float32, numpy=\n",
              "array([[ 0.0476017 , -0.03642512, -0.02449933, ..., -0.02889631,\n",
              "        -0.01723612, -0.01314093],\n",
              "       [ 0.02439922,  0.0304555 , -0.01999265, ..., -0.04715417,\n",
              "        -0.03328749, -0.02525299],\n",
              "       [ 0.00140228,  0.02744489, -0.042287  , ..., -0.03759339,\n",
              "        -0.00454023,  0.0016163 ],\n",
              "       ...,\n",
              "       [-0.00029685,  0.02801936, -0.02321785, ...,  0.00977889,\n",
              "        -0.02967455,  0.0495114 ],\n",
              "       [-0.00029685,  0.02801936, -0.02321785, ...,  0.00977889,\n",
              "        -0.02967455,  0.0495114 ],\n",
              "       [-0.00029685,  0.02801936, -0.02321785, ...,  0.00977889,\n",
              "        -0.02967455,  0.0495114 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tv_layer,\n",
        "    em_layer,\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(10),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation = 'relu')], name = 'lstm10_1')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV6yrvt2sLm0",
        "outputId": "b636da7c-dd25-4eba-ddb7-d9484ca98046"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"lstm10_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_3 (TextV  (None, 200)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 200, 16)           144576    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 200, 16)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 10)                1080      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 145,667\n",
            "Trainable params: 145,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = tf.keras.metrics.MeanAbsoluteError(name='mean_absolute_error', dtype=None)\n",
        "loss =  tf.keras.losses.MeanSquaredError()\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=loss,\n",
        "    metrics=[metric],\n",
        ")"
      ],
      "metadata": {
        "id": "L_LesX7-tBCm"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test if reviews pass through model, show sample output\n",
        "for ds in (ds_train, ds_test):  test_model(model, ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6iV5MOItlQ9",
        "outputId": "50d41171-39d5-49ee-acf5-2cd04b778955"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, tf.Tensor(\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]], shape=(8, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = ROOT + 'My_Models/' + model.name +'/'\n",
        "if not os.path.exists(ROOT + model_path):\n",
        "    os.makedirs(ROOT + model_path, exist_ok = False)\n",
        "    print('Created directory ' + ROOT + model_path)\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_path + 'checkpoints',\n",
        "    save_weights_only=True,\n",
        "    monitor='mean_absolute_error',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "QawtHaPHyvV9"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load from checkpoint\n",
        "# model.load_weights(model_path + 'checkpoints')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpsGSu_ninqG",
        "outputId": "ca56161f-5d3e-4bd3-b417-52bc30ab837b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ca14bdeb7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(model_path + 'current_weights.index'):\n",
        "    model.load_weights(model_path + 'current_weights')\n",
        "    print('Found previous weights')\n",
        "else:\n",
        "    print('No previous weights found!')\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs = 1000,\n",
        "    validation_data = ds_test,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")\n",
        "model.save_weights(model_path + 'current_weights', save_format='tf')\n",
        "print('Current weights saved to ' + model_path + 'current_weights')"
      ],
      "metadata": {
        "id": "-rRdOQPjtoGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# next(iter(ds_train))"
      ],
      "metadata": {
        "id": "wlmhYZDx1A2o"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(ds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwOehAb4tyUp",
        "outputId": "d649dba6-ae15-408d-ed6a-ad1e2cbd200d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 7ms/step - loss: 1.4832 - mean_absolute_error: 1.0329\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4831992387771606, 1.03293776512146]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(ROOT + 'data/models/lstm10')\n"
      ],
      "metadata": {
        "id": "K4Hjb3JiFLLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "#model.save(ROOT + 'data/models/lstm10.sav')"
      ],
      "metadata": {
        "id": "X6eL9JMjt8JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CuINhorVwSBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = fix_shape('the best hotel i ever stayed at')\n",
        "model.predict(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiFUuHp7t8Wm",
        "outputId": "dd01c907-a9a4-4c39-a00e-880c45c38274"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 395ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9284965]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\\\n",
        "the breakfast was excellent and the room very clean and spacious.\n",
        "the staff was very friendly.\n",
        "I can really recommend this place'''\n",
        "model.predict(fix_shape(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhjT5c3BuAWg",
        "outputId": "1c50e1a1-fd35-4669-8054-478020a6b9a1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.2970164]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\\\n",
        "the breakfast was excellent and the room very clean and spacious.\n",
        "the staff was very friendly.\n",
        "I can relly recommend this place'''\n",
        "model.predict(fix_shape(text))"
      ],
      "metadata": {
        "id": "8bcq7vj4uEXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\\\n",
        "the breakfast was ok, but nothing special.\n",
        "the staff was very friendly.\n",
        "But the room we small and not suitable for working'''\n",
        "\n",
        "model.predict(fix_shape(text))"
      ],
      "metadata": {
        "id": "1qYL5XXYuHKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\\\n",
        "the breakfast was ok, but nothing special.\n",
        "the staff was quite rude.\n",
        "And the room we small and not suitable for working'''\n",
        "model.predict(fix_shape(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDh1iPz1uMTV",
        "outputId": "a94d782e-c1d7-476d-e3dc-3f59e7046c40"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.2970164]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\\\n",
        "the breakfast was bad, only bread and coffe.\n",
        "Checkin took forever.\n",
        "No roomservice.\n",
        "The room we small and not suitable for working'''\n",
        "model.predict(fix_shape(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "PUYC7U55uNG-",
        "outputId": "d964fdb9-45f8-43cc-f466-885b108ddb8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fa338c7504e7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mNo\u001b[0m \u001b[0mroomservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m The room we small and not suitable for working'''\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfix_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuBoQBj42MOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}